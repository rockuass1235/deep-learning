
# 序

物件辨識在傳統技術上是一件很複雜的事情，對於圖片的預處理很多，而且效果上也很一般，甚至在有些情況下是無法辨識出來的。

因為電腦對於視覺處理並沒有和人類相同的概念，當我們強行用數學模型去建立幾何關係，並不能得到精準的值，物體的資訊不僅是幾何而已，像一個足球跟籃球我們能很輕易地分辨，電腦是不行的。



# Computer Vision

計算機視覺的研究目標是使計算機具備人類的視覺能力，能看懂圖像內容、理解動態場景，期望計算機能自動提取圖像、視頻等視覺數據中蘊含的層次化語義概念及多語義概念間的時空關聯等。

自2012 年以來，計算機視覺領域不斷湧現出很多激動人心的研究成果，例如，人臉識別、物體識別與分類等方面的性能已接近甚至超過人類視覺系統。因此，可以說計算機視覺當前發展已進入了一個新的階段。

梳理與歸納現階段計算機視覺的研究進展，不但有助於我們看清楚計算機視覺的研究現狀，而且對我們下一步的研究會起到重要的指導性作用。

遺憾的是，計算機視覺研究領域雖已有大量歸納和梳理研究進展的綜述性文章，但對2012 年以來計算機視覺研究進展進行綜述的文獻卻較為少見。



# 從特徵描述符到深度學習：計算機視覺發展20年


70年代中，MIT人工智能實驗室正式開設“機器視覺”課程，1977 年，David Marr提出了不同於“積木世界”分析方法的計算機視覺(computational vision)理論——也就是著名的Marr視覺理論，

該理論在80 年代成為機器視覺研究領域中的一個十分重要的理論框架。80年代開始，開始了全球性的研究熱潮，

計算機視覺的研究內容，大體可以分為物體視覺（object vision）和空間視覺（spatial vision）二大部分. 物體視覺在於對物體進行精細分類和鑑別，而空間視覺在於確定物體的位置和形狀，為“動作（action）” 服務。

馬爾的計算視覺分為三個層次： 計算理論、表達和算法以及算法實現。由於馬爾認為算法實現並不影響算法的功能和效果，所以，馬爾計算視覺理論主要討論“計算理論”和“表達與算法”二部分內容。

馬爾認為，大腦的神經計算和計算機的數值計算沒有本質區別，所以馬爾沒有對“算法實現”進行任何探討。

從現在神經科學的進展看，“神經計算(Neurl Network)”與數值計算(Machine Learning)在有些情況下會產生本質區別，如目前興起的神經形態計算（ Neuromorphological computing），但總體上說，“數值計算”可以“模擬神經計算”。

計算理論(Computational Theory) 需要明確視覺目的， **那麼視覺的主要功能是什麼 ?**

馬爾認為視覺不管有多少功能，主要功能在於 **從視網膜成像的二維圖像來恢復空間物體的可見三維表面形狀，稱之為“三維重建”（3D reconstruction）** 。

而且，馬爾認為，這種重建過程不是天生就有的，而是可以通過計算完成的。JJ Gibson 等心理學家，包括格式塔心裡學學派( Gestalt psychology)，認為視覺的很多功能是天生就有的。

可以想想，如果一種視覺功能與生具有，不可建模，就談不上計算，也許就不存在今天的“計算機視覺”這門學科了。

馬爾的計算理論認為，圖像是物理空間在視網膜上的投影，所以圖像信息蘊含了物理空間的內在信息，因此，任何計算視覺計算理論和方法都應該從圖像出發，充分挖掘圖像所蘊含的對應物理空間的內在屬性。

也就是說，馬爾的視覺計算理論就是要 **挖掘關於成像物理場景的內在屬性來完成相應的視覺問題計算** 。因為從數學的觀點看，僅僅從圖像出發，很多視覺問題具有“歧義性”，如典型的左右眼圖像之間的對應問題。

如果沒有任何先驗知識，圖像點對應關係不能唯一確定。不管任何動物或人，生活的環境都不是隨機的，不管有意識或無意識，時時刻刻都在利用這些先驗知識，來解釋看到的場景和指導日常的行為和行動。

如桌子上放一個水杯的場景，人們會正確地解釋為桌子上放了一個水杯，而不把他們看作一個新物體。當然，人類也會經常出錯，如大量錯覺現象。從這個意義上來說，讓計算機來模仿人類視覺是否一定是一條好的途徑也是一個未知的命題。

飛機的飛行需要藉助空氣動力學知識，而不是機械地模仿鳥如何飛。


### 表達和算法（Representationand Algorithm） 

識別物體之前，不管是計算機還是人，大腦（或計算機內存）中事先要有對該物體的存儲形式，稱之為物體表達（object representation）.

馬爾視覺計算理論認為，物體的表達形式為該物體的三維幾何形狀。馬爾當時猜測，由於人在識別物體時與觀察物體的視角無關，而不同視角下同一物體在視網膜上的成像又不同，所以物體在大腦中的表達不可能是二維的，可能是三維形狀，

因為三維形狀不依賴於觀察視角。另外，當時病理學研究發現，有些病人無法辨認“茶杯”，但可以毫無困難地畫出茶杯的形狀，因此馬爾覺得，這些病人也佐證了他的猜測。

從目前對大腦的研究看，大腦的功能是分區的。物體的“幾何形狀”和“語義”儲存在不同的腦區。另外，物體識別也不是絕對地與視角無關，僅僅在一個比較小的變化範圍內與視角無關。

所以，從當前的研究看，馬爾的物體的“三維表達”猜測基本上是不正確的，至少是不完全正確的，但馬爾的計算理論仍具有重要的理論意義和應用價值，至少現在證明大腦對圖像進行多層級的特徵抽取得到一組相對高維的向量特徵來進行分類與回歸處理。





### 視覺計算

在這樣的背景下，機器視覺開始研究如何從2維影像中抽取出內在屬性，形成類視覺皮層的底層局部表徵，如幾何特徵、區域邊界、物體輪廓和運動信息等，來進行各種任務。

然而自然界場景千變萬化，很難手工設計出能泛用任何情況的數學計算模型、相關演算法。


**1995年至2000年：局部特徵描述符的崛起**

早期底層視覺研究工作中用到的大部分特徵都是手工設計的，這些特徵以人的先驗知識為驅動，建立數學計算模型、相關演算法。

1999年當英屬哥倫比亞大學教授大衛·羅伊（David Lowe）提出SIFT（尺度不變特徵變換的縮寫，Scale Invariant Feature Transform）算法後，計算機視覺研究的世界幾乎在一夜之間發生了改變。

SIFT是一種對圖像塊進行抽取特徵後比較和匹配的解決方案。在大衛·羅伊沒有提出SIFT算法之前，人們通常只使用SSD（平方距離的總和）作為圖像塊比較的距離度量標準，對此並沒有太多的考慮。

SIFT又被稱為局部特徵描述符– 這是一個雄心勃勃的研究人員在圖像方面超過十年研究的成果之一。大衛·羅伊和英屬哥倫比亞大學為SIFT算法申請了專利，並且大衛·羅伊還在自己的主頁上公佈了SIFT實現的一條經過編譯後的二進製程序，

供研究人員在他們的工作中使用。SIFT允許一幅彩色圖像中的像素點或特徵點由一個低維向量進行表示。



![image](https://github.com/rockuass1235/deep-learning/blob/master/images/SIFT.png)



**當你通過旋轉照相機對同一物理拍攝不同角度的多幅圖像，這些對應點的SIFT描述符在其128維空間中非常相似。**

初看之下在進行圖像匹配之前需要進行如SIFT這麼複雜的處理似乎有點愚蠢，但是請相信我：那是因為你，作為一個人類，可以用肉眼觀看兩個圖像塊並迅速“理解”它們屬於同一個物體上的相同點，而這對於計算機來說是不同的。

SIFT對計算機視覺（包括立體視覺、從運動結恢復構等）的幾何方面的研究都有著重要的影響，後來還成為用於對象識別的流行的詞袋模型的基礎。

看到SIFT這樣的技術在圖像塊匹配上大大超過像平方距離求和（SSD）方法在每一個有抱負的視覺科學家的職業生涯的重要一步。

SIFT不只是濾波器響應的一個載體，其中的直方圖分級和規範化的步驟也是非常重要的。值得指出的是，雖然最初SIFT（在其論文中公佈的形式）主要作為興趣點檢測器的輸出，但是後來發現興趣點檢測步驟在對象分類問題中並不重要。

**對於分類問題，研究人員對圖像應用的是SIFT描述符的向量量化** 。


**2000年至2005年：箱、網格和視覺單詞（即面向描述符的機器學習）**

經過數年的發展，建立一個完美的(general)特徵抽取是不太可能的，專家開始轉向三種領域，設計更強的特徵抽取模式、仿生學習自動特徵抽取、基於統計的方法來對對物體進行表達特徵。

在2005，一個名叫Navneet Dalal的年輕研究人員向世界展示了用他自己設計的HOG特徵描述符能夠完成的功能。

HOG描述符是當每個人通過使用多層學習對詞袋應用運用空間分級，使得他們的系統過於復雜的時候出現的。Dalal巧妙設計的描述符其實本質上是比較簡單的。

HOG的論文是由Navneet和他的博士生導師Bill Triggs在2005年發表的。Bill Triggs因為早期在幾何視覺方面的研究而出名，Dalal博士則是由於他新發現的描述符而出名。

HOG描述符最初應用於行人檢測問題，之所以HOG描述如此受歡迎的原因是用在HOG上層使用機器學習工具非常簡單和容易理解，這種機器學習工具正是線性支持向量機(SVM)。


**2010至2015年：大數據，卷積神經網絡和深度學習**

自2012 年以來，深度學習逐漸在大規模圖像識別中取得了統治地位，關於深度學習有趣的是它是一種非常古老的技術。我們現在看到的深度學習本質上是神經網絡2.0的版本。

但這一次，我們的計算機和研究以及開發的速度要比原來快好幾個數量級。好笑的是現在倡導深度學習的人和90年代初倡導這種技術的同樣的一批研究人員。他們認為類神經網路能更好的詮釋何謂多聯級特徵抽取，並透過自我學習

得到比手工設計更好的特徵(內在屬性)抽取能力， 或者自動抽取最適合任務需求的特徵屬性。


![image](https://github.com/rockuass1235/deep-learning/blob/master/images/lenet.jpg)


# 總結

如今，深度學習幾乎成瞭如今計算機視覺研究的標配，人臉識別、圖像識別、視頻識別、行人檢測、大規模場景識別的相關論文裡都用到了深度學習的方法，深度學習可以做到傳統方法無法企及的精度，這是關鍵中的關鍵。

深度學習在2012年的時候在圖像識別領域有重大突破。目前計算機視覺在很多應用領域達到了實用水平，催生了工業界的大量應用。深度學習算法的通用性很強，基於深度學習的算法更加通用，

此外，深度學習獲得的特徵(feature)有很強的遷移能力。所謂特徵遷移能力，指的是在A任務上學習到一些特徵，在B任務上使用也可以獲得非常好的效果。例如在ImageNet（物體為主）上學習到的特徵在場景分類任務上也能取得非常好的效果。

最後，深度學習的工程開發、優化、維護成本低。深度學習計算主要是卷積和矩陣乘，針對這種計算優化，所有深度學習算法都可以提升性能。另外，通過組合現有的層(layer)，我們可以實現大量複雜網絡結構和一些算法，使其開發維護的成本低。





# 資料來源

https://zhuanlan.zhihu.com/p/64104497

https://blog.csdn.net/jkwwwwwwwwww/article/details/78619055

https://zhuanlan.zhihu.com/p/32116813

