# Convolution Layer

卷積神經網絡（convolutional neural network）是含有捲積層（convolutional layer）的神經網絡。最常見的二維卷積層。
它有高和寬兩個空間維度，常用來處理圖像數據。我們將介紹簡單形式的二維卷積層的工作原理。

在二維卷積層中，一個二維輸入數組和一個二維核（kernel）數組通過互相關運算輸出一個二維數組。我們用一個具體例子:

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv.gif)

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_formula.jpg)

它的物理意義大概可以理解為：系統某一時刻的輸出是由多個輸入共同作用（疊加）的結果。

卷積核上所有作用點依次作用於原始像素點後（即乘起來），線性疊加的輸出結果，即是最終卷積的輸出，也是我們想要的結果，我們稱為destination pixel.

（1）原始圖像通過與卷積核的數學運算，可以提取出圖像的某些指定特徵（features)。

（2）不同卷積核，提取的特徵也是不一樣的。

（3）提取的特徵一樣，不同的捲積核，效果也不一樣。

# Padding

當我們在用3x3 的捲積核在6x6 的圖像上執行卷積時，我們得到了4x4 的特徵圖。圖片變得縮小，假設我們補上邊使其成為8x8

再執行卷積時，特徵圖的大小就會變成6x6

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_pad.svg)

圖像為padding示意圖，在周圍補0不影響類神經網路訓練(疊加0)

所以我們得到以下公式:　　![image](https://github.com/rockuass1235/deep-learning/blob/master/images/padding_formula.jpg)

如果我們希望影像大小經過卷積核處理後大小不變，在擴充的寬度(padding)應該滿足下面的方程，其中p 是padding（填充），f 是卷積核的維度（通常是奇數）。


# Stride

在之前的例子中，我們總是將捲積核移動一個像素。但是，步長也可以看做是卷積層的一個參數。我們可以看到，如果我們使用更大的步長，卷積會成為什麼樣子。

在設計CNN 結構時，如果我們想降低輸出矩陣大小，那麼我們可以決定增大步長。考慮到擴充(p)和跨步(s)，輸出矩陣的大小可以使用下面的公式計算：

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/stride_formula.jpg)


![image](https://github.com/rockuass1235/deep-learning/blob/master/images/stride.gif)


所以我們歸納以下結論:

* 填充可以增加輸出的高和寬。這常用來使輸出與輸入具有相同的高和寬。
* 步幅可以減小輸出的高和寬，例如輸出的高和寬僅為輸入的高和寬的 1/n （ n 為大於1的整數）。

注: 在步幅的使用中，目前多以Max pooling 來進行縮小尺寸


# 多輸入通道和多輸出通道

前面我們用到的輸入和輸出都是二維數組，但真實數據的維度經常更高。例如，彩色圖像在高和寬2個維度外還有RGB（紅、綠、藍）3個顏色通道

立體卷積是一個非常重要的概念，它不僅讓我們能夠處理彩色圖像，而且更重要的是，可以在一個單獨的層上使用多個濾波器。最重要的規則是，濾波器和你想在其上應用濾波器的圖像必須擁有相同的通道數。



![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_multi_in.svg)

含2個輸入通道的互相關計算

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_3d.jpg)


儘管我們這次從第三個維度讓矩陣中的數值對相乘。如果我們想在同一張圖像上應用多個濾波器，我們會為每個濾波器獨立地計算卷積，然後將計算結果逐個堆疊，最後將他們組合成一個整體。得到的張量（3D矩陣可以被稱作張量 Tensor）



## 1 x 1 卷積層

1×1 卷積失去了卷積層可以識別高和寬維度上相鄰元素構成的模式的功能。實際上， 1×1 卷積的主要計算發生在通道維上。值得注意的是，輸入和輸出具有相同的高和寬。
輸出中的每個元素來自輸入中在高和寬上相同位置的元素在不同通道之間的按權重累加。假設我們將通道維當作特徵維，將高和寬維度上的元素當成數據樣本，那麼 1×1 卷積層的作用與全連接層等價。


![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_1x1.svg)

在之後的模型裡我們將會看到 1×1 卷積層被當作保持高和寬維度形狀不變的全連接層使用。於是，我們可以通過調整網絡層之間的通道數來控制模型複雜度。


# Fully Connect Layer & Convolution Layer

由於 **需要學習的參數數量巨大，全連接神經網絡在處理圖像方面是很弱的。** 既然我們已經了解了關於卷積的所有內容，讓我們來考慮一下它是如何優化計算的吧。

在下圖中，2D 卷積以一種稍微不同的方式進行了可視化——用數字1-9 標記的神經元組成接收後續像素亮度的輸入層，AD 這4 個單元代表的是計算得到的特徵圖元素。

最後但同等重要的是，I-IV 是卷積核中的數值——它們必須被學習到。現在，讓我們聚焦於卷積層的兩個重要屬性。

* 連續兩層中，並不是所有的神經元都是彼此相連的。例如，單元1 僅僅會影響到A 的值。
* 一些神經元會共享相同的權重。這兩個屬性都意味著我們要學習的參數數量要少很多。

順便說一下，值得注意的是，**濾波器中的每個值都會影響到特徵圖中的每個元素——這在反向傳播中是特別重要的**。

![image](https://github.com/rockuass1235/deep-learning/blob/master/images/conv_show.gif)




# 池化層 Pooling


除了卷積層，CNN 通常會用到所謂的池化層。它們最早被用來減小張量的大小以及加速運算。這些層是比較簡單的——我們需要將我們的圖像分成不同的區域，然後在每一個部分上執行一些運算。

例如，對Max Pool 層而言，我們會選擇每個區域的最大值，並將它放到對應的輸出區域。與卷積層的情況一樣，我們有兩個可用的超參數——濾波器大小和步長。

除此之外 池化（pooling）層的使用還有其他意義上的考量。回憶一下，圖像物體邊緣檢測應用中，我們構造卷積核從而精確地找到了像素變化的位置。如果我們構造的捲積核輸出，那麼說明輸入中和數值不一樣。這可能意味著物體邊緣通過這兩個元素之間。

但實際圖像裡，我們感興趣的物體不會總出現在固定位置：即使我們連續拍攝同一個物體也極有可能出現像素位置上的偏移。這會導致同一個邊緣對應的輸出可能出現在卷積輸出中的不同位置，進而造成訓練時模型劇烈變動無法收斂。

 池化（pooling）層，它的提出也是為了緩解卷積層對位置的過度敏感性。**讓資料從判斷邊緣變成輸出區域內價值最高的資訊**
 
 我們可以這麼認為，卷積的過程是勾勒圖片最小單元（特徵）的過程。其輸出值越大，表示該位置越貼近濾波器所代表的特徵。而MaxPooling的過程實在降低特徵在圖像位置上的精確程度。表示的是在該片區域存在該特徵。
 
 
 ## 從信號傳輸的角度來看的話，maxpooling是相當於把有用的信息過濾之後輸出，而minpooling是把信號中夾雜的噪聲作為輸出， average pooling則是把信號模糊化。





# 原文出處

https://zhuanlan.zhihu.com/p/63220482

https://zhuanlan.zhihu.com/p/30994790

https://zh.gluon.ai


